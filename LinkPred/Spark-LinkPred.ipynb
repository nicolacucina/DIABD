{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Creazione della sessione Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PageRank Recommendation System with Link Prediction\") \\\n",
    "    .getOrCreate()\n",
    "    # .config(\"spark.jars.packages\", \"graphframes:graphframes\") \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento dei dati\n",
    "ratings = spark.read.csv(\"hdfs://localhost:9000/test/ratings.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = spark.read.csv(\"hdfs://localhost:9000/test/movies.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.join(movies, on=\"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mappatura dei punteggi\n",
    "mapping_score = {\n",
    "    0.5: -1.0,\n",
    "    1: -1.0,\n",
    "    1.5: -0.5,\n",
    "    2: 0.0,\n",
    "    2.5: 0.0,\n",
    "    3: 0.0,\n",
    "    3.5: 0.5,\n",
    "    4: 1.0,\n",
    "    4.5: 1.1,\n",
    "    5: 1.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "map_score_udf = spark.udf.register(\"map_score\", lambda x: mapping_score.get(x, 0), FloatType())\n",
    "ratings = ratings.withColumn(\"weight\", map_score_udf(col(\"rating\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Creazione degli archi per il grafo (Utente -> Film)\n",
    "edges = ratings.select(\n",
    "    col(\"userId\").cast(StringType()).alias(\"src\"),\n",
    "    col(\"title\").alias(\"dst\"),\n",
    "    col(\"weight\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "# Creazione dei vertici (utenti e film)\n",
    "vertices_users = ratings.select(col(\"userId\").cast(StringType()).alias(\"id\")).distinct().withColumn(\"bipartite\", lit(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices_movies = ratings.select(col(\"title\").alias(\"id\")).distinct().withColumn(\"bipartite\", lit(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = vertices_users.union(vertices_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bans\\Desktop\\DIABD\\Python_3_11_9\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from graphframes import GraphFrame\n",
    "\n",
    "# Creazione del grafo\n",
    "user_movie_graph = GraphFrame(vertices, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proiezione del grafo: utente-utente e film-film\n",
    "user_user_edges = user_movie_graph.edges.alias(\"e1\") \\\n",
    "    .join(user_movie_graph.edges.alias(\"e2\"), col(\"e1.dst\") == col(\"e2.dst\")) \\\n",
    "    .select(\n",
    "        col(\"e1.src\").alias(\"src\"),\n",
    "        col(\"e2.src\").alias(\"dst\"),\n",
    "        (col(\"e1.weight\") + col(\"e2.weight\")).alias(\"weight\")\n",
    "    ).filter(col(\"src\") != col(\"dst\"))\n",
    "\n",
    "user_user_graph = GraphFrame(user_movie_graph.vertices, user_user_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_movie_edges = user_movie_graph.edges.alias(\"e1\") \\\n",
    "    .join(user_movie_graph.edges.alias(\"e2\"), col(\"e1.src\") == col(\"e2.src\")) \\\n",
    "    .select(\n",
    "        col(\"e1.dst\").alias(\"src\"),\n",
    "        col(\"e2.dst\").alias(\"dst\"),\n",
    "        (col(\"e1.weight\") + col(\"e2.weight\")).alias(\"weight\")\n",
    "    ).filter(col(\"src\") != col(\"dst\"))\n",
    "\n",
    "movie_movie_graph = GraphFrame(user_movie_graph.vertices, movie_movie_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per calcolare la similarità tra due film usando i vicini comuni\n",
    "def common_neighbors_similarity(movie1, movie2, user_movie_graph):\n",
    "    users1 = user_movie_graph.edges.filter(col(\"dst\") == movie1).select(\"src\").rdd.flatMap(lambda x: x).collect()\n",
    "    users2 = user_movie_graph.edges.filter(col(\"dst\") == movie2).select(\"src\").rdd.flatMap(lambda x: x).collect()\n",
    "    \n",
    "    # Calcolare i vicini comuni\n",
    "    common_users = set(users1).intersection(set(users2))\n",
    "    return len(common_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per predire i link tra un utente e un film\n",
    "def predict_links(user_id, movie_id, user_movie_graph):\n",
    "    movies = user_movie_graph.vertices.filter(col(\"bipartite\") == 1).select(\"id\").rdd.map(lambda row: row[0]).collect()\n",
    "    \n",
    "    similarity_scores = []\n",
    "    for movie in movies:\n",
    "        if movie != movie_id:\n",
    "            score = common_neighbors_similarity(movie_id, movie, user_movie_graph)\n",
    "            similarity_scores.append((movie, score))\n",
    "    \n",
    "    # Ordina i film in base alla similarità\n",
    "    similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarity_scores[:10]  # Restituisci i 10 film più simili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per creare il vettore di preferenze per un utente\n",
    "def create_preference_vector(user_id, user_movie_graph):\n",
    "    edges = user_movie_graph.edges.filter(col(\"src\") == user_id).rdd.map(lambda row: (row[\"dst\"], row[\"weight\"])).collect()\n",
    "    print(f\"Preference vector for user {user_id}: {list(edges)[:10]}\")\n",
    "\n",
    "    tot = sum([weight for _, weight in edges])\n",
    "    \n",
    "    if tot > 0:\n",
    "        return {movie: weight / tot for movie, weight in edges}\n",
    "    else:\n",
    "        movies = user_movie_graph.vertices.filter(col(\"bipartite\") == 1).select(\"id\").rdd.map(lambda row: row[0]).collect()\n",
    "        return {movie: 1 / len(movies) for movie in movies}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per prevedere i film per un utente\n",
    "def predict_user(user_id, user_movie_graph, movie_movie_graph):\n",
    "    p_vec = create_preference_vector(user_id, user_movie_graph)\n",
    "    already_seen = [movie for movie, weight in p_vec.items() if weight > 0]\n",
    "    \n",
    "    # Predici i film che l'utente potrebbe apprezzare\n",
    "    predicted_links = []\n",
    "    for movie in already_seen:\n",
    "        similar_movies = predict_links(user_id, movie, user_movie_graph)\n",
    "        for movie_id, score in similar_movies:\n",
    "            if movie_id not in already_seen:\n",
    "                predicted_links.append((movie_id, score))\n",
    "    \n",
    "    # Calcola il PageRank per i film\n",
    "    pagerank_results = movie_movie_graph.pageRank(resetProbability=0.95, maxIter=20)\n",
    "    item_rank = pagerank_results.vertices.select(\"id\", \"pagerank\").rdd.map(lambda row: (row[\"id\"], row[\"pagerank\"])).collectAsMap()\n",
    "    \n",
    "    # Combina le raccomandazioni\n",
    "    recommendations = sorted(predicted_links, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Ordina i film in base al punteggio di PageRank\n",
    "    recommendations += sorted(\n",
    "        (movie for movie in item_rank if movie not in already_seen),\n",
    "        key=lambda x: item_rank[x], reverse=True\n",
    "    )\n",
    "    \n",
    "    return recommendations[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preference vector for user 10: [('Pulp Fiction (1994)', -1.0), ('Forrest Gump (1994)', 0.5), ('Aladdin (1992)', 1.0), ('Pretty Woman (1990)', 0.5), ('Casablanca (1942)', 1.0), ('Mary Poppins (1964)', -1.0), ('Dirty Dancing (1987)', 0.0), ('Graduate, The (1967)', 0.0), ('When Harry Met Sally... (1989)', 0.0), ('As Good as It Gets (1997)', 0.5)]\n"
     ]
    }
   ],
   "source": [
    "user = \"10\"\n",
    "recommended_movies = predict_user(user, user_movie_graph, movie_movie_graph)\n",
    "print(f\"Recommended movies for user {user}: {recommended_movies[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit, size, collect_list\n",
    "from pyspark.sql.types import IntegerType, FloatType, StringType"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
