{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serve python 3.11.9\n",
    "import os \n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/10 17:13:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/01/10 17:14:00 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('SVD Big') \\\n",
    "    .master('yarn') \\\n",
    "    .config('spark.driver.memory', '4g') \\\n",
    "    .config('spark.executor.instances', '3') \\\n",
    "    .config('spark.executor.memory', '6g') \\\n",
    "    .config(\"spark.locality.wait.node\", \"0\") \\\n",
    "    .config(\"spark.sql.pivotMaxValues\", \"99999\") \\\n",
    "    .getOrCreate()\n",
    "    # driver non serve così grande \n",
    "    # pivot max values \n",
    "    # .config('spark.executor.instances', '2') \\\n",
    "    #.config('spark.executor.memoryOverhead', '2g') \\\n",
    "    #.config(\"spark.hadoop.fs.defaultFS\", \"hdfs://localhost:50054\") \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 3.5.4\n"
     ]
    }
   ],
   "source": [
    "# Test the spark session\n",
    "print(f\"Spark Version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.app.submitTime', '1736333609136'),\n",
       " ('spark.app.startTime', '1736333609501'),\n",
       " ('spark.driver.extraJavaOptions',\n",
       "  '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false'),\n",
       " ('spark.driver.appUIAddress', 'http://master:4040'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS',\n",
       "  'master'),\n",
       " ('spark.driver.host', 'master'),\n",
       " ('spark.locality.wait.node', '0'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.app.id', 'application_1736332895337_0001'),\n",
       " ('spark.executor.memory', '6g'),\n",
       " ('spark.executor.memoryOverhead', '2g'),\n",
       " ('spark.master', 'yarn'),\n",
       " ('spark.sql.pivotMaxValues', '99999'),\n",
       " ('spark.app.name', 'SVD Big'),\n",
       " ('spark.driver.memory', '6g'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.executor.instances', '2'),\n",
       " ('spark.executor.extraJavaOptions',\n",
       "  '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.driver.port', '34271'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.yarn.isPython', 'true'),\n",
       " ('spark.executorEnv.PYTHONPATH',\n",
       "  '{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.9.7-src.zip'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES',\n",
       "  'http://master:8088/proxy/application_1736332895337_0001'),\n",
       " ('spark.ui.filters',\n",
       "  'org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext._conf.getAll()  # check the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs_port = 9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ratings = spark.read.csv('hdfs://master:'+ str(hdfs_port) +'/dataset/ratings.csv', header=True, inferSchema=True)\n",
    "#ratings = spark.read.csv('hdfs://master:'+ str(hdfs_port) +'/dataset/ratingsBig.csv', header=True, inferSchema=True)\n",
    "ratings.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.drop('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1        1     4.0\n",
       "1       1        3     4.0\n",
       "2       1        6     4.0\n",
       "3       1       47     5.0\n",
       "4       1       50     5.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "num_users = ratings.select(\"userId\").distinct().count()\n",
    "num_movies = ratings.select(\"movieId\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610\n",
      "9724\n"
     ]
    }
   ],
   "source": [
    "print(num_users)\n",
    "print(num_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = spark.read.csv('hdfs://master:'+ str(hdfs_port) +'/dataset/movies.csv', header=True, inferSchema=True)\n",
    "#movies = spark.read.csv('hdfs://master:'+ str(hdfs_port) +'/dataset/moviesBig.csv', header=True, inferSchema=True)\n",
    "movies.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Heat (1995)</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Seven (a.k.a. Se7en) (1995)</td>\n",
       "      <td>Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>Crime|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  userId  rating                        title  \\\n",
       "0        1       1     4.0             Toy Story (1995)   \n",
       "1        3       1     4.0      Grumpier Old Men (1995)   \n",
       "2        6       1     4.0                  Heat (1995)   \n",
       "3       47       1     5.0  Seven (a.k.a. Se7en) (1995)   \n",
       "4       50       1     5.0   Usual Suspects, The (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                               Comedy|Romance  \n",
       "2                        Action|Crime|Thriller  \n",
       "3                             Mystery|Thriller  \n",
       "4                       Crime|Mystery|Thriller  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_movie_ratings = ratings.join(movies, on='movieId', how='inner')\n",
    "user_movie_ratings.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 11.226202487945557 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "user_movie_ratings_pivot = user_movie_ratings.groupBy(\"userId\").pivot(\"movieId\").max(\"rating\").fillna(0)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/10 16:35:23 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "25/01/10 16:35:28 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "25/01/10 16:35:34 WARN DAGScheduler: Broadcasting large task binary with size 7.4 MiB\n",
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>193565</th>\n",
       "      <th>193567</th>\n",
       "      <th>193571</th>\n",
       "      <th>193573</th>\n",
       "      <th>193579</th>\n",
       "      <th>193581</th>\n",
       "      <th>193583</th>\n",
       "      <th>193585</th>\n",
       "      <th>193587</th>\n",
       "      <th>193609</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>471</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9725 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId    1    2    3    4    5    6    7    8    9  ...  193565  193567  \\\n",
       "0     463  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       "1     148  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       "2     471  5.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       "3     496  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       "4     540  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       "\n",
       "   193571  193573  193579  193581  193583  193585  193587  193609  \n",
       "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 9725 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_movie_ratings_pivot.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(user_movie_ratings_pivot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/10 17:17:20 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "25/01/10 17:17:24 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "[Stage 20:>                                                         (0 + 1) / 1]"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.linalg.distributed import CoordinateMatrix\n",
    "\n",
    "temp = user_movie_ratings_pivot.rdd.map(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "\n",
    "temp_Rows = RowMatrix(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/10 17:17:57 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:18:11 WARN RowMatrix: The input data is not directly cached, which may hurt performance if its parent RDDs are also uncached.\n",
      "25/01/10 17:18:11 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.arpack.JNIARPACK\n",
      "25/01/10 17:18:14 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:18:27 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:18:38 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:18:49 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:19:01 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:19:12 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:19:24 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:19:35 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:19:47 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:19:58 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:20:10 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:20:20 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:20:31 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:20:42 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:20:53 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:21:03 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:21:13 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:21:23 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:21:33 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:21:42 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:21:51 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:21:59 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:22:08 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:22:17 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:22:26 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:22:34 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:22:42 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:22:50 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:22:59 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:23:07 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:23:15 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:23:23 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:23:30 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:23:38 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:23:46 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:23:54 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:24:02 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:24:09 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:24:17 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:24:24 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:24:32 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:24:40 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:24:48 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:24:55 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:25:03 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:25:11 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:25:19 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:25:27 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:25:34 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:25:42 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:25:50 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:25:59 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:26:06 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:26:14 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:26:22 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:26:30 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:26:38 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:26:46 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:26:54 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:27:01 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:27:09 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:27:17 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:27:25 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:27:33 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:27:41 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:27:48 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:27:56 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:28:04 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:28:12 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:28:19 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:28:27 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:28:34 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:28:42 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:28:49 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:28:57 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:29:04 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:29:13 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:29:20 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:29:27 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:29:34 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "25/01/10 17:29:42 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "[Stage 266:>                                                        (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 712.7905120849609 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/10 17:29:49 WARN RowMatrix: The input data was not directly cached, which may hurt performance if its parent RDDs are also uncached.\n"
     ]
    }
   ],
   "source": [
    "k = 20\n",
    "start_time = time.time()\n",
    "svd= temp_Rows.computeSVD(k, computeU=True)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = svd.U  # RowMatrix\n",
    "\n",
    "num_rows_U = U.numRows() \n",
    "num_cols_U = len(s)\n",
    "print(\"Dim matrice U:\", num_rows_U,\"x\", num_cols_U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(U.rows.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = svd.s  # DenseVector\n",
    "num_values_s = len(s)\n",
    "print(\"Dim matrice S:\", num_values_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8715.254040390664,430.66003946141376,230.3788472265473,181.44393394518877,163.28636239451632,153.82002599951502,146.85492016634328,134.61133915340173,122.65670927470916,121.36767523102908,113.09990478390701,109.1314684760936,107.89709023215889,105.48233406374217,101.62980571860767,99.81198283034432,99.26946681656825,97.09582747304856,93.36879143710415,92.24948301358381]\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = svd.V  # DenseMatrix\n",
    "\n",
    "num_rows_V = V.numRows  # Numero di righe di V\n",
    "num_cols_V = V.numCols  # Numero di colonne di V\n",
    "print(\"Dim matrice V:\", num_rows_V, \"x\", num_cols_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseMatrix([[ 9.99279559e-01, -3.53312555e-02,  2.53591031e-03, ...,\n",
      "              -3.21291236e-04, -3.76444606e-04, -5.10174839e-04],\n",
      "             [ 3.42252350e-03,  5.54252970e-02, -2.25570771e-02, ...,\n",
      "              -2.43450049e-03, -1.42151584e-02, -2.81342608e-02],\n",
      "             [ 1.66228674e-03,  3.37532887e-02, -1.48811343e-04, ...,\n",
      "              -1.68999584e-03,  5.44739834e-03,  1.70020413e-02],\n",
      "             ...,\n",
      "             [ 8.48140142e-06, -2.16343807e-05,  6.23134881e-04, ...,\n",
      "               7.57944951e-05,  8.16376194e-05,  9.26359228e-05],\n",
      "             [ 8.48140142e-06, -2.16343807e-05,  6.23134881e-04, ...,\n",
      "               7.57944951e-05,  8.16376194e-05,  9.26359228e-05],\n",
      "             [ 1.74565034e-05,  1.63420109e-04,  1.31813185e-03, ...,\n",
      "              -3.89118583e-04,  8.98424983e-04,  4.28757431e-04]],\n",
      "            shape=(9725, 20))\n"
     ]
    }
   ],
   "source": [
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim matrice U: 610 x 20\n",
      "Dim matrice S: 20\n",
      "Dim matrice V: 9725 x 20\n",
      "Memoria occupata da U: 0.09 MB\n",
      "Memoria occupata da S: 0.00 MB\n",
      "Memoria occupata da V: 1.48 MB\n",
      "Memoria totale: 1.58 MB\n"
     ]
    }
   ],
   "source": [
    "# Check memory occupation\n",
    "\n",
    "bytes_per_float = 8\n",
    "\n",
    "memory_U = num_rows_U * num_cols_U * bytes_per_float\n",
    "memory_S = num_values_s * bytes_per_float\n",
    "memory_V = num_rows_V * num_cols_V * bytes_per_float\n",
    "\n",
    "total_memory = memory_U + memory_S + memory_V\n",
    "\n",
    "print(f\"Memoria occupata da U: {memory_U / (1024**2):.2f} MB\")\n",
    "print(f\"Memoria occupata da S: {memory_S / (1024**2):.2f} MB\")\n",
    "print(f\"Memoria occupata da V: {memory_V / (1024**2):.2f} MB\")\n",
    "print(f\"Memoria totale: {total_memory / (1024**2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data la compressione ottuneta dal calcolo di SVD (le matrici occupano qualche MB di memoria), è possibile utilizzare python per calcolare il prodotto matriciale tramite numpy e ricostruire la matrice.\n",
    "Per effettuare il ranking dei film da consigliare si può utilizzare un approccio simile ad ALS, quindi filtrare la riga dell'utente scelto per i film che non ha visto e prendere i primi dieci ordinati per valore ricostruito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
